{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vN99YjPTDena"
   },
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZIx_naXnDyHd"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjnmdyPLD2tS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6c8YExmOD5x5"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQOdXhjXD_AE"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../Datasets/insurance.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 19 27.9 0]\n",
      " [0.0 1.0 1.0 ... 18 33.77 1]\n",
      " [0.0 1.0 1.0 ... 28 33.0 3]\n",
      " ...\n",
      " [1.0 0.0 1.0 ... 18 36.85 0]\n",
      " [1.0 0.0 1.0 ... 21 25.8 0]\n",
      " [1.0 0.0 0.0 ... 61 29.07 0]]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding: turn string column into 3 different columns (countries), for 3 different categories\n",
    "# Bindary vector: each country to a certain order of the columns\n",
    "\n",
    "# Coding independent variable\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create object of the column transformer class\n",
    "# [0] is the index of column to apply OneHotEncoding\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,5])], remainder='passthrough')\n",
    "\n",
    "# Apply the transform method to change the column X\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ud_1XTb28iXH"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUib_pbl8ipB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rb5nWuSHEfBV"
   },
   "source": [
    "## Training the Polynomial Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYplp4pTEm0O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_reg = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "regressor = LinearRegression(normalize=True)\n",
    "regressor.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pzF3BRps9nlk"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36aFLFBK9pMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12136.    9724.53]\n",
      " [10542.    8547.69]\n",
      " [48248.   45702.02]\n",
      " [12890.   12950.07]\n",
      " [ 9674.    9644.25]\n",
      " [ 3706.    4500.34]\n",
      " [ 3514.    2198.19]\n",
      " [15746.   11436.74]\n",
      " [11938.    7537.16]\n",
      " [ 8410.    5425.02]\n",
      " [ 8524.    6753.04]\n",
      " [14276.   10493.95]\n",
      " [ 8880.    7337.75]\n",
      " [ 5634.    4185.1 ]\n",
      " [24014.   18310.74]\n",
      " [11916.   10702.64]\n",
      " [12922.   12523.6 ]\n",
      " [ 4816.    3490.55]\n",
      " [ 9434.    6457.84]\n",
      " [30330.   33475.82]\n",
      " [25490.   23967.38]\n",
      " [16218.   12643.38]\n",
      " [12090.   23045.57]\n",
      " [28330.   23065.42]\n",
      " [ 5610.    1674.63]\n",
      " [ 6082.    4667.61]\n",
      " [ 3194.    3732.63]\n",
      " [ 8832.    7682.67]\n",
      " [ 5362.    3756.62]\n",
      " [11554.    8413.46]\n",
      " [12594.    8059.68]\n",
      " [51518.   48970.25]\n",
      " [12986.   12979.36]\n",
      " [10938.   20630.28]\n",
      " [16106.   14571.89]\n",
      " [ 6362.    4137.52]\n",
      " [11224.    8347.16]\n",
      " [37342.   51194.56]\n",
      " [37130.   40003.33]\n",
      " [ 1298.    1880.49]\n",
      " [ 5994.    5458.05]\n",
      " [ 6874.    2867.12]\n",
      " [26362.   20149.32]\n",
      " [46160.   47496.49]\n",
      " [35602.   36149.48]\n",
      " [ 5426.   26018.95]\n",
      " [11890.   19749.38]\n",
      " [ 9178.    6940.91]\n",
      " [ 6348.    4718.2 ]\n",
      " [13030.   22192.44]\n",
      " [ 5098.    2899.49]\n",
      " [ 6026.   18838.7 ]\n",
      " [30496.   23568.27]\n",
      " [51626.   46255.11]\n",
      " [11970.   24227.34]\n",
      " [ 4442.    3268.85]\n",
      " [ 6474.    2322.62]\n",
      " [10170.    8827.21]\n",
      " [ 8816.   14478.33]\n",
      " [14452.   13112.6 ]\n",
      " [ 3226.    1253.94]\n",
      " [39432.   46718.16]\n",
      " [15808.   13919.82]\n",
      " [11664.    9630.4 ]\n",
      " [12536.   10736.87]\n",
      " [ 8736.    9880.07]\n",
      " [27066.   32548.34]\n",
      " [35966.   38746.36]\n",
      " [ 2046.    3180.51]\n",
      " [12118.    8162.72]\n",
      " [13818.   13041.92]\n",
      " [14464.   11554.22]\n",
      " [23258.   16232.85]\n",
      " [14562.   13887.97]\n",
      " [13818.   13012.21]\n",
      " [14026.   13217.09]\n",
      " [10122.    7147.1 ]\n",
      " [10868.    7731.43]\n",
      " [28536.   20296.86]\n",
      " [45246.   47403.88]\n",
      " [13018.   11658.38]\n",
      " [53050.   45863.21]\n",
      " [ 2954.    2055.32]\n",
      " [10104.    7441.05]\n",
      " [41626.   41034.22]\n",
      " [20574.   18972.49]\n",
      " [  316.    3410.32]\n",
      " [ 3962.    2699.57]\n",
      " [14542.   12333.83]\n",
      " [36442.   36837.47]\n",
      " [10314.    6334.34]\n",
      " [12522.   10214.64]\n",
      " [ 4714.   17878.9 ]\n",
      " [10116.    8515.76]\n",
      " [ 5754.    4518.83]\n",
      " [ 8366.    5148.55]\n",
      " [36762.   42303.69]\n",
      " [32608.   38998.55]\n",
      " [ 8274.    5327.4 ]\n",
      " [10178.   10602.39]\n",
      " [ 5802.    1824.29]\n",
      " [ 7654.    5377.46]\n",
      " [ 5276.    4349.46]\n",
      " [36906.   37742.58]\n",
      " [29510.   32787.46]\n",
      " [ 3482.    3353.47]\n",
      " [13018.   10577.09]\n",
      " [ 4282.    3556.92]\n",
      " [11386.   11944.59]\n",
      " [40122.   52590.83]\n",
      " [16550.   12475.35]\n",
      " [ 5602.    4266.17]\n",
      " [12100.    9249.5 ]\n",
      " [31674.   33732.69]\n",
      " [52306.   48675.52]\n",
      " [ 8612.    7729.65]\n",
      " [ 3516.    1964.78]\n",
      " [11362.    8444.47]\n",
      " [12808.   12347.17]\n",
      " [12692.    9301.89]\n",
      " [39262.   42124.52]\n",
      " [10106.    9991.04]\n",
      " [11754.   14319.03]\n",
      " [ 7022.    5428.73]\n",
      " [ 9454.    7626.99]\n",
      " [ 6650.    4906.41]\n",
      " [31738.   23401.31]\n",
      " [20562.   21098.55]\n",
      " [49018.   48173.36]\n",
      " [ 2362.    1917.32]\n",
      " [ 9950.    8219.2 ]\n",
      " [ 4436.    1725.55]\n",
      " [ 7962.    5976.83]\n",
      " [ 8026.    9361.33]\n",
      " [31930.   22144.03]\n",
      " [31194.   35491.64]\n",
      " [22346.   19515.54]\n",
      " [11050.   10107.22]\n",
      " [21614.   23244.79]\n",
      " [ 4110.    2789.06]\n",
      " [ 2442.    2261.57]\n",
      " [11738.   10594.5 ]\n",
      " [12180.    9304.7 ]\n",
      " [10362.   10435.07]\n",
      " [ 6760.    4894.75]\n",
      " [15010.   14313.85]\n",
      " [13982.   28287.9 ]\n",
      " [ 5424.   14426.07]\n",
      " [ 1114.    1627.28]\n",
      " [10648.   25517.11]\n",
      " [ 9470.    6555.07]\n",
      " [45946.   39611.76]\n",
      " [10704.    9964.06]\n",
      " [ 4296.    1720.35]\n",
      " [ 2506.    2730.11]\n",
      " [ 8504.    6500.24]\n",
      " [ 4044.    2643.27]\n",
      " [ 4214.    1719.44]\n",
      " [15948.   11085.59]\n",
      " [14728.   10115.01]\n",
      " [ 6330.    4846.92]\n",
      " [15322.   12982.87]\n",
      " [13978.   28923.14]\n",
      " [ 9522.    9391.35]\n",
      " [ 5258.    4544.23]\n",
      " [ 6108.   17128.43]\n",
      " [14058.   13844.51]\n",
      " [10116.    6113.23]\n",
      " [ 5276.    4441.21]\n",
      " [ 1810.    1633.96]\n",
      " [ 6342.    4058.71]\n",
      " [ 5258.    4435.09]\n",
      " [12132.    8310.84]\n",
      " [ 5978.    1986.93]\n",
      " [ 5314.    4260.74]\n",
      " [ 4798.    4504.66]\n",
      " [ 4106.    4428.89]\n",
      " [ 7532.    6117.49]\n",
      " [38334.   30184.94]\n",
      " [ 1626.    1708.93]\n",
      " [15020.   11187.66]\n",
      " [10232.    6796.86]\n",
      " [12314.   11356.66]\n",
      " [ 6746.    2498.41]\n",
      " [ 5642.   27375.9 ]\n",
      " [31674.   28101.33]\n",
      " [ 3162.    2254.8 ]\n",
      " [ 2996.    2597.78]\n",
      " [15226.   14692.67]\n",
      " [14102.   10370.91]\n",
      " [37530.   41097.16]\n",
      " [ 4654.    3981.98]\n",
      " [ 7194.    5472.45]\n",
      " [23354.   21223.68]\n",
      " [ 3450.    2534.39]\n",
      " [ 4522.    1972.95]\n",
      " [ 7902.    6406.41]\n",
      " [10658.    6551.75]\n",
      " [ 6610.    4058.12]\n",
      " [ 6306.    4243.59]\n",
      " [14160.   11512.41]\n",
      " [42650.   46889.26]\n",
      " [15922.   12268.63]\n",
      " [22612.   19199.94]\n",
      " [ 6892.    4433.39]\n",
      " [41710.   42969.85]\n",
      " [ 4156.   23241.47]\n",
      " [13130.    9140.95]\n",
      " [ 7064.    5836.52]\n",
      " [ 3546.    1149.4 ]\n",
      " [11184.    8765.25]\n",
      " [14842.   14043.48]\n",
      " [ 8602.    5312.17]\n",
      " [ 2030.   10795.94]\n",
      " [ 9108.    6282.23]\n",
      " [ 4458.    1969.61]\n",
      " [ 7974.    6746.74]\n",
      " [ 7164.    5354.07]\n",
      " [14962.   14001.29]\n",
      " [ 7718.    6877.98]\n",
      " [ 5308.    6196.45]\n",
      " [11226.    7986.48]\n",
      " [ 9698.    8277.52]\n",
      " [ 4426.    3206.49]\n",
      " [11994.   11848.14]\n",
      " [13898.   14210.54]\n",
      " [13356.   12265.51]\n",
      " [13106.   11837.16]\n",
      " [ 7090.    6652.53]\n",
      " [ 5594.    2137.65]\n",
      " [ 4634.    1131.51]\n",
      " [ 9160.    8342.91]\n",
      " [13530.   12244.53]\n",
      " [ 7582.    4561.19]\n",
      " [ 5466.   17626.24]\n",
      " [ 8974.    6875.96]\n",
      " [12126.    9447.38]\n",
      " [31514.   34254.05]\n",
      " [ 7040.    6067.13]\n",
      " [14292.   11729.68]\n",
      " [ 6946.    5383.54]\n",
      " [35082.   37465.34]\n",
      " [ 7224.    7371.77]\n",
      " [ 9082.    7325.05]\n",
      " [12096.    8410.05]\n",
      " [12716.   10461.98]\n",
      " [ 3458.    3279.87]\n",
      " [10248.    7727.25]\n",
      " [ 3738.    2731.91]\n",
      " [ 6898.    6858.48]\n",
      " [25026.   19521.97]\n",
      " [41454.   47305.31]\n",
      " [ 3644.    3987.93]\n",
      " [ 3114.    3238.44]\n",
      " [ 3898.    7323.73]\n",
      " [  826.    1704.57]\n",
      " [ 9540.    7445.92]\n",
      " [ 2266.    1629.83]\n",
      " [ 7164.    4877.98]\n",
      " [ 4000.    3561.89]\n",
      " [ 8986.    8605.36]\n",
      " [30864.   24520.26]\n",
      " [40410.   45710.21]\n",
      " [18498.   15019.76]\n",
      " [ 9074.    6664.69]\n",
      " [10650.   20709.02]\n",
      " [40246.   40932.43]\n",
      " [10154.    9500.57]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(poly_reg.transform(X_test))\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fz1uTlWV919-"
   },
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvZQ_4W893-e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8659089703391487"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score \n",
    "degrees = [2, 3, 4, 5, 6] # Change degree \"hyperparameter\" here\n",
    "normalizes = [True, False] # Change normalize hyperparameter here\n",
    "best_score = 0\n",
    "best_degree = 0\n",
    "for degree in degrees:\n",
    "    for normalize in normalizes:\n",
    "        poly_features = PolynomialFeatures(degree = degree)\n",
    "        X_train_poly = poly_features.fit_transform(X_train)\n",
    "        polynomial_regressor = LinearRegression(normalize=normalize)\n",
    "        polynomial_regressor.fit(X_train_poly, y_train)\n",
    "        scores = cross_val_score(polynomial_regressor, X_train_poly, y_train, cv=5) # Change k-fold cv value here\n",
    "        if max(scores) > best_score:\n",
    "            best_score = max(scores)\n",
    "            best_degree = degree\n",
    "            best_normalize = normalize\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8560595979126553\n",
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_normalize)\n",
    "print(best_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "polynomial_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
